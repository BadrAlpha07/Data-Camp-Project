{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1> \n",
    "        Data Camp Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <center>\n",
    "    <h1> \n",
    "        Scrapping Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "    <em>\n",
    "        See 'scrapping/scrapping_functions.py' file for the designed functions\n",
    "    </em>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installing & Importing dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Packages required \n",
    "* import sys\n",
    "* requests\n",
    "* html5lib\n",
    "* bs4\n",
    "* bs4 selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from parse import search\n",
    "from selenium import webdriver\n",
    "# Designed scrapping functions see 'scrapping_functions.py' \n",
    "from scrapping_functions import Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and set path to chromedriver\n",
    "driver_path = r\"chromedriver.exe\"\n",
    "#For Instagram Scrapping (can be changed)\n",
    "user_name = \"datacamp1020\"\n",
    "password= \"$datacamp1020$\"\n",
    "#Define our Scrapper\n",
    "scrapper = Scrapper(user_name, password, driver_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieving top 49 World Influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://fr.m.wikipedia.org/wiki/Liste_des_comptes_Instagram_les_plus_suivis\n",
    "influencers_int, links_int = scrapper.get_influencers_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = influencers_int.to_csv (r'C:\\Users\\basti\\DataCamp\\Projet_Groupe_vclean\\data\\0_influencers_list\\influencer_list_world.csv', index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieving influencers infos and their posts' links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can select only a few numbers of influencers to retrieve posts from\n",
    "#links_int_1 = links_int[0:10]\n",
    "#influencers_int_1 = influencers_int[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames=[]\n",
    "pause_time = 3\n",
    "for i in range(len(links_int)):\n",
    "    print(links_int[i])\n",
    "    if i == 0:\n",
    "        browser = scrapper.connection_instagram()\n",
    "    df = scrapper.get_influencer_posts(influencers_int,i, browser, links_int[i], pause_time)\n",
    "    data_frames.append(df)\n",
    "links_pub_int = pd.concat(data_frames)\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_pub_int = pd.concat(data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = links_pub_int.to_csv(r'C:\\Users\\basti\\DataCamp\\Projet_Groupe_vclean\\data\\1_publications_list\\publications_list.csv', index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieving posts' infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = pd.read_csv(r'C:\\Users\\basti\\DataCamp\\Projet_Groupe_vclean\\data\\1_publications_list\\publications_list.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_post = [] \n",
    "browser = scrapper.connection_instagram()\n",
    "for pub_link in publications[\"Links to publication\"]: \n",
    "    print(publications[publications[\"Links to publication\"]==pub_link].index[0])\n",
    "    df = scrapper.get_pub_info(pub_link,browser)\n",
    "    df_post.append(df)\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_info = pd.concat(df_post, ignore_index = True)\n",
    "posts_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.merge(publications, post_info, how ='right', on =\"Links to publication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = df_2.to_csv (r'C:\\Users\\basti\\DataCamp\\Projet_Groupe_vclean\\data\\2_raw_data\\raw_final_dataset.csv', index = None, header=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
